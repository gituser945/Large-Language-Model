{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using ChatGPT with Python for simple real-world tasks using Prompt Engineering"
      ],
      "metadata": {
        "id": "fb6rdwlCsCGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook you will use the OpenAI's ChatGPT to solve:\n",
        "\n",
        "- Task 1: Zero-shot Classification\n",
        "- Task 2: Few-shot Classification\n",
        "- Task 3: Coding Tasks - Python\n",
        "- Task 4: Coding Tasks - SQL\n",
        "- Task 5: Information Extraction\n",
        "- Task 6: Closed-Domain Question Answering\n",
        "- Task 7: Open-Domain Question Answering\n",
        "- Task 8: Document Summarization\n",
        "- Task 9: Transformation\n",
        "- Task 10: Translation\n",
        "\n",
        "\n",
        "\n",
        "___Created By: Dipanjan (DJ)___"
      ],
      "metadata": {
        "id": "XTzBUFWQ-OWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenAI dependencies"
      ],
      "metadata": {
        "id": "L1KvMtf54l0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "2evPp14fy258",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a9c7440-000c-49c7-9544-da5192b72a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.13-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load OpenAI API Credentials\n"
      ],
      "metadata": {
        "id": "CiwGjVWK4q6F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryheOZuXxa41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95ecc93-71f2-47f2-ed57-639fd8382739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "openai_key = getpass(\"Enter your OpenAI API Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from IPython.display import HTML\n",
        "\n",
        "openai.api_key = openai_key"
      ],
      "metadata": {
        "id": "kDe44J0N0NcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create ChatGPT Completion Access Function\n",
        "\n",
        "This function will use the [Chat Completion API](https://platform.openai.com/docs/api-reference/chat/create) to access ChatGPT for us and return responses\n"
      ],
      "metadata": {
        "id": "VDWhgxCy5bA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "kA9gVCwK0WKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's try out the ChatGPT API!"
      ],
      "metadata": {
        "id": "1TFZjzuGjCOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(prompt='Explain Generative AI in 2 bullet points')\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK-kjmMoi5rO",
        "outputId": "e6b7c57d-8c35-42a7-efd3-5480e0915c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Generative AI is a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on.\n",
            "- This technology can be used in a variety of applications, including creating realistic images for video games, generating personalized content for marketing campaigns, or even composing music or writing stories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Zero-shot Classification\n",
        "\n",
        "This prompt tests an LLM's text classification capabilities by prompting it to classify a piece of text without providing any examples.\n",
        "\n"
      ],
      "metadata": {
        "id": "AeDkpvGDhMGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = [\n",
        "    f\"\"\"\n",
        "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
        "    The sound quality is impressively clear with just the right amount of bass.\n",
        "    It's also waterproof, which tested true during a recent splashing incident.\n",
        "    Though it's compact, the volume can really fill the space.\n",
        "    The price was a bargain for such high-quality sound.\n",
        "    Shipping was also on point, arriving two days early in secure packaging.\n",
        "    \"\"\",\n",
        "    f\"\"\"\n",
        "    Needed a new kitchen blender, but this model has been a nightmare.\n",
        "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
        "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
        "    I thought the brand meant quality, but this product has proven me wrong.\n",
        "    Plus, it arrived three days late. Definitely not worth the expense.\n",
        "    \"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "hRbBZB57hT0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses = []\n",
        "\n",
        "for review in reviews:\n",
        "  prompt = f\"\"\"\n",
        "              Act as a product review analyst.\n",
        "              Given the following review,\n",
        "              Display the overall sentiment for the review as only one of the following:\n",
        "              Positive, Negative OR Neutral\n",
        "\n",
        "              ```{review}```\n",
        "              \"\"\"\n",
        "  response = get_completion(prompt)\n",
        "  responses.append(response)"
      ],
      "metadata": {
        "id": "jZwPaViatl7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for response in responses:\n",
        "  print(response)\n",
        "  print('------')\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "EdUFkKAmtmBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd91f59-ba57-4cb3-8e14-55488baa0a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n",
            "------\n",
            "\n",
            "\n",
            "Negative\n",
            "------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Few-shot Classification\n",
        "\n",
        "This prompt tests an LLM's text classification capabilities by prompting it to classify a piece of text by providing a few examples of inputs and outputs.\n",
        "\n"
      ],
      "metadata": {
        "id": "6WC6aycZ9Qe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "responses = []\n",
        "\n",
        "for review in reviews:\n",
        "  prompt = f\"\"\"\n",
        "              Act as a product review analyst.\n",
        "              Given the following review,\n",
        "              Display only the overall sentiment for the review:\n",
        "\n",
        "              Try to classify it by using the following examples as a reference:\n",
        "\n",
        "              Review: Just received the Laptop I ordered for work, and it's amazing.\n",
        "              Sentiment: 😊\n",
        "\n",
        "              Review: Needed a new mechanical keyboard, but this model has been totally disappointing.\n",
        "              Sentiment: 😡\n",
        "\n",
        "              Review: ```{review}```\n",
        "              \"\"\"\n",
        "  response = get_completion(prompt)\n",
        "  responses.append(response)"
      ],
      "metadata": {
        "id": "kQZdygfUoXGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for response in responses:\n",
        "  print(response)\n",
        "  print('------')\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCsMzs3QodqR",
        "outputId": "d6ddd2dd-287f-4326-f1e8-11a44db24070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: 😊\n",
            "------\n",
            "\n",
            "\n",
            "Sentiment: 😡\n",
            "------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3: Coding Tasks - Python\n",
        "\n",
        "This prompt tests an LLM's capabilities for generating python code based on various tasks\n"
      ],
      "metadata": {
        "id": "HEKTyfWf9cxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Act as an expert in generating python code\n",
        "\n",
        "Your task is to generate python code\n",
        "to build a classification model for a fraud detection dataset\n",
        "use sklearn to build a pipeline using random forest\n",
        "\"\"\"\n",
        "response = get_completion(prompt)"
      ],
      "metadata": {
        "id": "6xawr-Co9b0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "2Cenat0G9-Bw",
        "outputId": "b12d5f56-0e83-4fec-f008-0e9065979355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Sure, here is an example of Python code to build a classification model for a fraud detection dataset using sklearn and random forest:\n\n```python\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\n\n# Load the dataset\ndata = pd.read_csv('fraud_detection_dataset.csv')\n\n# Split the data into features and target variable\nX = data.drop('fraud_label', axis=1)\ny = data['fraud_label']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a pipeline with StandardScaler and RandomForestClassifier\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('rf', RandomForestClassifier())\n])\n\n# Fit the pipeline on the training data\npipeline.fit(X_train, y_train)\n\n# Make predictions on the test data\npredictions = pipeline.predict(X_test)\n\n# Calculate the accuracy of the model\naccuracy = accuracy_score(y_test, predictions)\nprint(f'Accuracy of the model: {accuracy}')\n```\n\nMake sure to replace 'fraud_detection_dataset.csv' with the actual file path of your dataset. This code will preprocess the data using StandardScaler and build a classification model using Random Forest algorithm. Finally, it will output the accuracy of the model on the test data."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(prompt, model='gpt-4o')"
      ],
      "metadata": {
        "id": "kuQivgcV-J1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "LVjvz6Ow-OXd",
        "outputId": "fba33192-93d5-413a-83a6-22c828318f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Certainly! Below is an example of how you can build a classification model for a fraud detection dataset using a pipeline with a Random Forest classifier in Python with scikit-learn.\n\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Load your dataset\n# Assuming you have a CSV file named 'fraud_detection.csv'\n# and the target column is named 'is_fraud'\ndata = pd.read_csv('fraud_detection.csv')\n\n# Separate features and target\nX = data.drop(columns=['is_fraud'])\ny = data['is_fraud']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a pipeline with a StandardScaler and RandomForestClassifier\npipeline = Pipeline([\n    ('scaler', StandardScaler()),  # Standardize the features\n    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # Random Forest Classifier\n])\n\n# Train the model\npipeline.fit(X_train, y_train)\n\n# Make predictions\ny_pred = pipeline.predict(X_test)\n\n# Evaluate the model\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# Save the model if needed\nimport joblib\njoblib.dump(pipeline, 'fraud_detection_model.pkl')\n```\n\n### Explanation:\n1. **Loading the Dataset**: The dataset is loaded using `pandas.read_csv()`. Adjust the file path and target column name as necessary.\n2. **Splitting the Data**: The data is split into training and testing sets using `train_test_split()`.\n3. **Pipeline Creation**: A pipeline is created with two steps:\n   - `StandardScaler` to standardize the features.\n   - `RandomForestClassifier` to perform the classification.\n4. **Model Training**: The pipeline is fitted to the training data.\n5. **Predictions and Evaluation**: Predictions are made on the test set, and the model's performance is evaluated using accuracy and a classification report.\n6. **Model Saving**: The trained model is saved using `joblib.dump()` for future use.\n\nMake sure to adjust the file path, target column name, and any other parameters as needed for your specific dataset and requirements."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4: Coding Tasks - SQL\n",
        "\n",
        "This prompt tests an LLM's capabilities for generating SQL code based on various tasks"
      ],
      "metadata": {
        "id": "0JoSF5wb_Imw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Act as an expert in generating SQL code.\n",
        "\n",
        "Understand the following schema of the database tables carefully:\n",
        "Table departments, columns = [DepartmentId, DepartmentName]\n",
        "Table employees, columns = [EmployeeId, EmployeeName, DepartmentId]\n",
        "Table salaries, columns = [EmployeeId, Salary]\n",
        "\n",
        "Create a MySQL query for the employee with max salary in the 'IT' Department.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)"
      ],
      "metadata": {
        "id": "4XKGZIG3_Tjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "4cFqsBtSA7Wx",
        "outputId": "5422a14b-7ee7-4246-fcfd-9fa657ab06a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Sure, here is the MySQL query to find the employee with the maximum salary in the 'IT' department:\n\n```sql\nSELECT e.EmployeeId, e.EmployeeName, s.Salary\nFROM employees e\nJOIN salaries s ON e.EmployeeId = s.EmployeeId\nWHERE e.DepartmentId = (SELECT DepartmentId FROM departments WHERE DepartmentName = 'IT')\nORDER BY s.Salary DESC\nLIMIT 1;\n```\n\nThis query will retrieve the EmployeeId, EmployeeName, and Salary of the employee with the highest salary in the 'IT' department. It first joins the employees and salaries tables on the EmployeeId column, filters the employees by the 'IT' department, orders the results by salary in descending order, and then limits the output to only the top result."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(prompt, model='gpt-4o')\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "YOsR2k9fGw2j",
        "outputId": "7dcce771-e98e-4b86-870f-e3f2248d548c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Certainly! To find the employee with the maximum salary in the 'IT' department, you can use the following MySQL query. This query involves joining the `departments`, `employees`, and `salaries` tables, and then filtering and sorting the results to get the desired output.\n\nHere's the query:\n\n```sql\nSELECT e.EmployeeId, e.EmployeeName, s.Salary\nFROM employees e\nJOIN salaries s ON e.EmployeeId = s.EmployeeId\nJOIN departments d ON e.DepartmentId = d.DepartmentId\nWHERE d.DepartmentName = 'IT'\nORDER BY s.Salary DESC\nLIMIT 1;\n```\n\n### Explanation:\n1. **JOIN Clause**: \n   - `JOIN salaries s ON e.EmployeeId = s.EmployeeId`: This joins the `employees` table with the `salaries` table on the `EmployeeId` column.\n   - `JOIN departments d ON e.DepartmentId = d.DepartmentId`: This joins the `employees` table with the `departments` table on the `DepartmentId` column.\n\n2. **WHERE Clause**: \n   - `WHERE d.DepartmentName = 'IT'`: This filters the results to include only those employees who belong to the 'IT' department.\n\n3. **ORDER BY Clause**: \n   - `ORDER BY s.Salary DESC`: This sorts the results in descending order based on the salary.\n\n4. **LIMIT Clause**: \n   - `LIMIT 1`: This limits the result to only the top record, which is the employee with the highest salary in the 'IT' department.\n\nThis query will return the `EmployeeId`, `EmployeeName`, and `Salary` of the employee with the maximum salary in the 'IT' department."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5: Information Extraction\n",
        "\n",
        "This prompt tests an LLM's capabilities for extracting and analyzing key entities from documents"
      ],
      "metadata": {
        "id": "-mck_SlcM3bG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clinical_note = \"\"\"\n",
        "60-year-old man in NAD with a h/o CAD, DM2, asthma, pharyngitis, SBP,\n",
        "and HTN on altace for 8 years awoke from sleep around 1:00 am this morning\n",
        "with a sore throat and swelling of the tongue.\n",
        "He came immediately to the ED because he was having difficulty swallowing and\n",
        "some trouble breathing due to obstruction caused by the swelling.\n",
        "He did not have any associated SOB, chest pain, itching, or nausea.\n",
        "He has not noticed any rashes.\n",
        "He says that he feels like it is swollen down in his esophagus as well.\n",
        "He does not recall vomiting but says he might have retched a bit.\n",
        "In the ED he was given 25mg benadryl IV, 125 mg solumedrol IV,\n",
        "and pepcid 20 mg IV.\n",
        "Family history of CHF and esophageal cancer (father).\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UxciK2wsIw3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Act as an expert in analyzing and understanding clinical doctor notes in healthcare.\n",
        "Extract all symptoms only from the text below.\n",
        "Differentiate between symptoms that are present vs. absent.\n",
        "Give me the probability (high/ medium/ low) of how sure you are about the result.\n",
        "Add a note on the probabilities and why you think so.\n",
        "\n",
        "Output as a markdown table with the following columns,\n",
        "all symptoms should be expanded and no acronyms unless you don't know:\n",
        "\n",
        "Symptoms | Present/Denies | Probability.\n",
        "\n",
        "Also expand all acronyms.\n",
        "Output that also as a separate appendix table in Markdown.\n",
        "\n",
        "Clinical Note:\n",
        "```{clinical_note}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)"
      ],
      "metadata": {
        "id": "GcazKzm0JGKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "pqXCxmtEJl4h",
        "outputId": "b781ec21-54f5-482c-9a76-1d98612bade5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "| Symptoms           | Present/Denies | Probability |\n|--------------------|-----------------|-------------|\n| Sore throat        | Present         | High        |\n| Swelling of the tongue | Present      | High        |\n| Difficulty swallowing | Present       | High        |\n| Trouble breathing  | Present         | High        |\n| Obstruction        | Present         | High        |\n| Swelling in esophagus | Present       | High        |\n| Retching           | Present         | High        |\n| Itching            | Denies          | High        |\n| Nausea             | Denies          | High        |\n| Chest pain         | Denies          | High        |\n| Rash               | Denies          | High        |\n\n**Note on Probabilities:**\nThe probabilities assigned are high because the symptoms mentioned in the clinical note are explicitly stated and directly observed by the healthcare provider. The absence of certain symptoms is also clearly mentioned, increasing the certainty of the analysis.\n\nAppendix Table:\n\n| Abbreviation | Expanded Form        |\n|--------------|----------------------|\n| NAD          | No acute distress    |\n| CAD          | Coronary artery disease |\n| DM2          | Diabetes mellitus type 2 |\n| SBP          | Systolic blood pressure |\n| HTN          | Hypertension          |\n| ED           | Emergency Department  |\n| IV           | Intravenous          |\n| CHF          | Congestive heart failure |"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(prompt, model='gpt-4o')\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "8OkPl7k1JwuT",
        "outputId": "5c146247-83a8-4c2c-bd72-c98bc3100878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Symptoms Table\n\n| Symptoms                        | Present/Denies | Probability |\n|---------------------------------|----------------|-------------|\n| Sore throat                     | Present        | High        |\n| Swelling of the tongue          | Present        | High        |\n| Difficulty swallowing           | Present        | High        |\n| Trouble breathing               | Present        | High        |\n| Feeling of swelling in esophagus| Present        | High        |\n| Retching                        | Present        | Medium      |\n| Shortness of breath             | Denies         | High        |\n| Chest pain                      | Denies         | High        |\n| Itching                         | Denies         | High        |\n| Nausea                          | Denies         | High        |\n| Rashes                          | Denies         | High        |\n| Vomiting                        | Denies         | Medium      |\n\n### Probabilities Note\n- **High Probability**: The symptoms are explicitly mentioned in the clinical note with clear context, making it highly likely that the interpretation is accurate.\n- **Medium Probability**: The symptoms are mentioned with some ambiguity or less certainty, such as \"might have retched a bit,\" which introduces some doubt.\n\n### Appendix Table\n\n| Acronym   | Expanded Form                  |\n|-----------|--------------------------------|\n| NAD       | No Acute Distress              |\n| h/o       | History of                     |\n| CAD       | Coronary Artery Disease        |\n| DM2       | Type 2 Diabetes Mellitus       |\n| SBP       | Systolic Blood Pressure        |\n| HTN       | Hypertension                   |\n| ED        | Emergency Department           |\n| SOB       | Shortness of Breath            |\n| CHF       | Congestive Heart Failure       |\n| IV        | Intravenous                    |\n| mg        | Milligrams                     |\n\nThis structured format should help in understanding the symptoms and their presence or absence, along with the confidence level in the interpretation."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 6: Closed-Domain Question Answering\n",
        "\n",
        "Question Answering (QA) is a natural language processing task which involves generating the desired answer for the given question. Question Answering can be open-domain QA or closed-domain QA depending on whether the LLM is provided with the relevant context or not.\n",
        "\n",
        "In the case of closed-domain QA, a question along with relevant context is given. Here the context is nothing but the relevant text which ideally should have the answer. Just like a RAG workflow."
      ],
      "metadata": {
        "id": "_jucY6L9w14Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report = \"\"\"\n",
        "Three quarters (77%) of the population saw an increase in their regular outgoings over the past year,\n",
        "according to findings from our recent consumer survey. In contrast, just over half (54%) of respondents\n",
        "had an increase in their salary, which suggests that the burden of costs outweighing income remains for\n",
        "most. In total, across the 2,500 people surveyed, the increase in outgoings was 18%, three times higher\n",
        "than the 6% increase in income.\n",
        "\n",
        "Despite this, the findings of our survey suggest we have reached a plateau. Looking at savings,\n",
        "for example, the share of people who expect to make regular savings this year is just over 70%,\n",
        "broadly similar to last year. Over half of those saving plan to use some of the funds for residential\n",
        "property. A third are saving for a deposit, and a further 20% for an investment property or second home.\n",
        "\n",
        "But for some, their plans are being pushed back. 9% of respondents stated they had planned to purchase\n",
        "a new home this year but have now changed their mind. While for many the deposit may be an issue,\n",
        "the other driving factor remains the cost of the mortgage, which has been steadily rising the last\n",
        "few years. For those that currently own a property, the survey showed that in the last year,\n",
        "the average mortgage payment has increased from £668.51 to £748.94, or 12%.\"\"\"\n"
      ],
      "metadata": {
        "id": "8I7ZsP3OxL-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "How much has the average mortage payment increased in the last year?\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Using the following context information below please answer the following question\n",
        "to the best of your ability\n",
        "Context:\n",
        "{report}\n",
        "Question:\n",
        "{question}\n",
        "Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "dAPf8hD2xATM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(prompt)\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "whY2mBoXxUPM",
        "outputId": "259b9e6b-1e59-4b55-d846-f93fd2e44e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The average mortgage payment has increased by 12% in the last year, from £668.51 to £748.94."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(prompt, model='gpt-4o')\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "eNE7OYO9xZOk",
        "outputId": "528e552a-ecd4-46ba-94ed-678675988036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The average mortgage payment has increased by £80.43 in the last year, from £668.51 to £748.94, which is a 12% increase."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "What percentage of people had an increase in salary last year? Show the answer just as a number.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Using the following context information below please answer the following question\n",
        "to the best of your ability\n",
        "Context:\n",
        "{report}\n",
        "Question:\n",
        "{question}\n",
        "Answer:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "A-Dxn9d_xibD",
        "outputId": "9ad2dc7a-53dd-4cd4-d5a7-b727b25a7ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "54%"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(prompt, model='gpt-4o')\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "NJ57GoXAxjkP",
        "outputId": "fdd55b98-0778-4dfa-b04e-b9e123583555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "54"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 7: Open-Domain Question Answering\n",
        "\n",
        "Question Answering (QA) is a natural language processing task which involves generating the desired answer for the given question.\n",
        "\n",
        "In the case of open-domain QA, only the question is asked without providing any context or information. Here, the LLM answers the question using the knowledge gained from large volumes of text data during its training. This is basically Zero-Shot QA"
      ],
      "metadata": {
        "id": "EuQlsSmWxyCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Please answer the following question to the best of your ability\n",
        "Question:\n",
        "What is LangChain?\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "fV2MP4OdyETp",
        "outputId": "c00096ba-a58e-47d1-fec6-1c34ad89afac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "LangChain is a blockchain platform that focuses on language-related applications and services. It aims to provide a decentralized ecosystem for language learning, translation, and other language-related activities. The platform utilizes blockchain technology to ensure transparency, security, and efficiency in language-related transactions and interactions."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(prompt, model='gpt-4o')\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "OSC-IhDmyRYg",
        "outputId": "0a4754e7-deaf-42b7-80cd-1a8a428eb4a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "LangChain is a framework designed to facilitate the development of applications that leverage large language models (LLMs). It provides a suite of tools and abstractions that make it easier to build complex applications by integrating LLMs with various data sources, APIs, and other computational resources. LangChain is particularly useful for tasks such as natural language processing, text generation, and conversational AI, among others. By offering a structured approach to combining LLMs with other components, LangChain helps developers create more robust and scalable language-based applications."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 8: Document Summarization\n",
        "\n",
        "Document summarization is a natural language processing task which involves creating a concise summary of the given text, while still capturing all the important information."
      ],
      "metadata": {
        "id": "tnVmXCZAzyux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = \"\"\"\n",
        "Coronaviruses are a large family of viruses which may cause illness in animals or humans.\n",
        "In humans, several coronaviruses are known to cause respiratory infections ranging from the\n",
        "common cold to more severe diseases such as Middle East Respiratory Syndrome (MERS) and Severe Acute Respiratory Syndrome (SARS).\n",
        "The most recently discovered coronavirus causes coronavirus disease COVID-19.\n",
        "COVID-19 is the infectious disease caused by the most recently discovered coronavirus.\n",
        "This new virus and disease were unknown before the outbreak began in Wuhan, China, in December 2019.\n",
        "COVID-19 is now a pandemic affecting many countries globally.\n",
        "The most common symptoms of COVID-19 are fever, dry cough, and tiredness.\n",
        "Other symptoms that are less common and may affect some patients include aches\n",
        "and pains, nasal congestion, headache, conjunctivitis, sore throat, diarrhea,\n",
        "loss of taste or smell or a rash on skin or discoloration of fingers or toes.\n",
        "These symptoms are usually mild and begin gradually.\n",
        "Some people become infected but only have very mild symptoms.\n",
        "Most people (about 80%) recover from the disease without needing hospital treatment.\n",
        "Around 1 out of every 5 people who gets COVID-19 becomes seriously ill and develops difficulty breathing.\n",
        "Older people, and those with underlying medical problems like high blood pressure, heart and lung problems,\n",
        "diabetes, or cancer, are at higher risk of developing serious illness.\n",
        "However, anyone can catch COVID-19 and become seriously ill.\n",
        "People of all ages who experience fever and/or  cough associated with difficulty breathing/shortness of breath,\n",
        "chest pain/pressure, or loss of speech or movement should seek medical attention immediately.\n",
        "If possible, it is recommended to call the health care provider or facility first,\n",
        "so the patient can be directed to the right clinic.\n",
        "People can catch COVID-19 from others who have the virus.\n",
        "The disease spreads primarily from person to person through small droplets from the nose or mouth,\n",
        "which are expelled when a person with COVID-19 coughs, sneezes, or speaks.\n",
        "These droplets are relatively heavy, do not travel far and quickly sink to the ground.\n",
        "People can catch COVID-19 if they breathe in these droplets from a person infected with the virus.\n",
        "This is why it is important to stay at least 1 meter) away from others.\n",
        "These droplets can land on objects and surfaces around the person such as tables, doorknobs and handrails.\n",
        "People can become infected by touching these objects or surfaces, then touching their eyes, nose or mouth.\n",
        "This is why it is important to wash your hands regularly with soap and water or clean with alcohol-based hand rub.\n",
        "Practicing hand and respiratory hygiene is important at ALL times and is the best way to protect others and yourself.\n",
        "When possible maintain at least a 1 meter distance between yourself and others.\n",
        "This is especially important if you are standing by someone who is coughing or sneezing.\n",
        "Since some infected persons may not yet be exhibiting symptoms or their symptoms may be mild,\n",
        "maintaining a physical distance with everyone is a good idea if you are in an area where COVID-19 is circulating.\"\"\""
      ],
      "metadata": {
        "id": "dY53sXf_ymwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "You are an expert in generating accurate document summaries.\n",
        "Generate a summary of the given document.\n",
        "\n",
        "Document:\n",
        "{doc}\n",
        "\n",
        "\n",
        "Constraints: Please start the summary with the delimiter 'Summary'\n",
        "and limit the summary to 5 lines\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "7upxVwh5y8te",
        "outputId": "494ebcc2-1f0d-4c37-d9ac-90379ca6727f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Summary: Coronaviruses can cause respiratory illnesses in humans, with COVID-19 being the most recent strain. Symptoms include fever, cough, and fatigue, with some experiencing more severe symptoms. The virus spreads through respiratory droplets and contact with contaminated surfaces. Maintaining good hygiene and physical distance is crucial in preventing the spread of COVID-19."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(prompt, model='gpt-4o')\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "6ga-Hf59zWWT",
        "outputId": "7b1963ec-00fc-4e3f-fd7e-8a2bd327d799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Summary:\nCoronaviruses are a large family of viruses that can cause illnesses in humans, ranging from the common cold to severe diseases like MERS and SARS. The most recently discovered coronavirus causes COVID-19, which emerged in Wuhan, China, in December 2019 and has since become a global pandemic. Common symptoms include fever, dry cough, and tiredness, with severe cases leading to difficulty breathing. COVID-19 spreads primarily through respiratory droplets, making hand hygiene and maintaining physical distance crucial. Older adults and individuals with underlying health conditions are at higher risk of severe illness."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 9: Transformation\n",
        "\n",
        "You can use LLMs to take an existing document and transform it into other formats of content and even generate training data for fine-tuning or training models"
      ],
      "metadata": {
        "id": "keC5k5S-18cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fact_sheet_mobile = \"\"\"\n",
        "PRODUCT NAME\n",
        "Samsung Galaxy Z Fold4 5G Black\n",
        "​\n",
        "PRODUCT OVERVIEW\n",
        "Stands out. Stands up. Unfolds.\n",
        "The Galaxy Z Fold4 does a lot in one hand with its 15.73 cm(6.2-inch) Cover Screen.\n",
        "Unfolded, the 19.21 cm(7.6-inch) Main Screen lets you really get into the zone.\n",
        "Pushed-back bezels and the Under Display Camera means there's more screen\n",
        "and no black dot getting between you and the breathtaking Infinity Flex Display.\n",
        "Do more than more with Multi View. Whether toggling between texts or catching up\n",
        "on emails, take full advantage of the expansive Main Screen with Multi View.\n",
        "PC-like power thanks to Qualcomm Snapdragon 8+ Gen 1 processor in your pocket,\n",
        "transforms apps optimized with One UI to give you menus and more in a glance\n",
        "New Taskbar for PC-like multitasking. Wipe out tasks in fewer taps. Add\n",
        "apps to the Taskbar for quick navigation and bouncing between windows when\n",
        "you're in the groove.4 And with App Pair, one tap launches up to three apps,\n",
        "all sharing one super-productive screen\n",
        "Our toughest Samsung Galaxy foldables ever. From the inside out,\n",
        "Galaxy Z Fold4 is made with materials that are not only stunning,\n",
        "but stand up to life's bumps and fumbles. The front and rear panels,\n",
        "made with exclusive Corning Gorilla Glass Victus+, are ready to resist\n",
        "sneaky scrapes and scratches. With our toughest aluminum frame made with\n",
        "Armor Aluminum, this is one durable smartphone.\n",
        "World’s first water resistant foldable smartphones. Be adventurous, rain\n",
        "or shine. You don't have to sweat the forecast when you've got one of the\n",
        "world's first water-resistant foldable smartphones.\n",
        "​\n",
        "PRODUCT SPECS\n",
        "OS - Android 12.0\n",
        "RAM - 12 GB\n",
        "Product Dimensions - 15.5 x 13 x 0.6 cm; 263 Grams\n",
        "Batteries - 2 Lithium Ion batteries required. (included)\n",
        "Item model number - SM-F936BZKDINU_5\n",
        "Wireless communication technologies - Cellular\n",
        "Connectivity technologies - Bluetooth, Wi-Fi, USB, NFC\n",
        "GPS - True\n",
        "Special features - Fast Charging Support, Dual SIM, Wireless Charging, Built-In GPS, Water Resistant\n",
        "Other display features - Wireless\n",
        "Device interface - primary - Touchscreen\n",
        "Resolution - 2176x1812\n",
        "Other camera features - Rear, Front\n",
        "Form factor - Foldable Screen\n",
        "Colour - Phantom Black\n",
        "Battery Power Rating - 4400\n",
        "Whats in the box - SIM Tray Ejector, USB Cable\n",
        "Manufacturer - Samsung India pvt Ltd\n",
        "Country of Origin - China\n",
        "Item Weight - 263 g\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ta182I2t2FD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt =f\"\"\"Turn the following product description into a list of frequently asked questions (FAQ).\n",
        "Show both the question and it's corresponding answer\n",
        "\n",
        "Product description:\n",
        "```{fact_sheet_mobile}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "zko53u-N2KmD",
        "outputId": "1c290027-2a76-41e3-b677-3d87f4c87587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "1. Is the Samsung Galaxy Z Fold4 5G Black water resistant?\n- Yes, it is one of the world's first water-resistant foldable smartphones.\n\n2. What are the dimensions and weight of the Samsung Galaxy Z Fold4 5G Black?\n- The product dimensions are 15.5 x 13 x 0.6 cm and it weighs 263 grams.\n\n3. What operating system does the Samsung Galaxy Z Fold4 5G Black run on?\n- It runs on Android 12.0.\n\n4. How much RAM does the Samsung Galaxy Z Fold4 5G Black have?\n- It has 12 GB of RAM.\n\n5. What special features does the Samsung Galaxy Z Fold4 5G Black have?\n- It supports fast charging, has dual SIM capabilities, wireless charging, built-in GPS, and is water resistant.\n\n6. What is included in the box with the Samsung Galaxy Z Fold4 5G Black?\n- The box includes a SIM Tray Ejector and a USB Cable.\n\n7. What is the battery power rating of the Samsung Galaxy Z Fold4 5G Black?\n- The battery power rating is 4400.\n\n8. What are the connectivity technologies of the Samsung Galaxy Z Fold4 5G Black?\n- It has Bluetooth, Wi-Fi, USB, and NFC connectivity technologies.\n\n9. What is the item model number of the Samsung Galaxy Z Fold4 5G Black?\n- The item model number is SM-F936BZKDINU_5.\n\n10. What is the color of the Samsung Galaxy Z Fold4 5G Black?\n- The color is Phantom Black."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(prompt, model='gpt-4o')\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "95cIhtf22N21",
        "outputId": "d9c49315-1b60-4cfd-d5bd-7545b72afad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Frequently Asked Questions (FAQ)\n\n**Q1: What is the name of the product?**\n- A1: The product is called Samsung Galaxy Z Fold4 5G Black.\n\n**Q2: What are the dimensions of the Cover Screen and Main Screen?**\n- A2: The Cover Screen is 15.73 cm (6.2 inches) and the Main Screen is 19.21 cm (7.6 inches).\n\n**Q3: What processor does the Galaxy Z Fold4 use?**\n- A3: The Galaxy Z Fold4 uses the Qualcomm Snapdragon 8+ Gen 1 processor.\n\n**Q4: What is Multi View and how does it work?**\n- A4: Multi View allows you to toggle between texts or catch up on emails, taking full advantage of the expansive Main Screen by displaying multiple apps simultaneously.\n\n**Q5: What is the Taskbar feature?**\n- A5: The Taskbar feature allows for PC-like multitasking, enabling quick navigation and bouncing between windows. You can add apps to the Taskbar for easier access.\n\n**Q6: How durable is the Galaxy Z Fold4?**\n- A6: The Galaxy Z Fold4 is made with Corning Gorilla Glass Victus+ on the front and rear panels and an Armor Aluminum frame, making it resistant to scrapes, scratches, and bumps.\n\n**Q7: Is the Galaxy Z Fold4 water-resistant?**\n- A7: Yes, the Galaxy Z Fold4 is one of the world's first water-resistant foldable smartphones.\n\n**Q8: What operating system does the Galaxy Z Fold4 run on?**\n- A8: The Galaxy Z Fold4 runs on Android 12.0.\n\n**Q9: How much RAM does the Galaxy Z Fold4 have?**\n- A9: The Galaxy Z Fold4 has 12 GB of RAM.\n\n**Q10: What are the product dimensions and weight?**\n- A10: The product dimensions are 15.5 x 13 x 0.6 cm, and it weighs 263 grams.\n\n**Q11: What type of batteries does the Galaxy Z Fold4 use?**\n- A11: The Galaxy Z Fold4 requires 2 Lithium Ion batteries, which are included.\n\n**Q12: What wireless communication technologies are supported?**\n- A12: The Galaxy Z Fold4 supports Cellular, Bluetooth, Wi-Fi, USB, and NFC.\n\n**Q13: Does the Galaxy Z Fold4 have GPS?**\n- A13: Yes, the Galaxy Z Fold4 has built-in GPS.\n\n**Q14: What special features does the Galaxy Z Fold4 offer?**\n- A14: Special features include Fast Charging Support, Dual SIM, Wireless Charging, Built-In GPS, and Water Resistance.\n\n**Q15: What is the screen resolution of the Galaxy Z Fold4?**\n- A15: The screen resolution is 2176x1812.\n\n**Q16: What type of cameras does the Galaxy Z Fold4 have?**\n- A16: The Galaxy Z Fold4 has both rear and front cameras.\n\n**Q17: What is the form factor of the Galaxy Z Fold4?**\n- A17: The form factor is a foldable screen.\n\n**Q18: What color is the Galaxy Z Fold4 available in?**\n- A18: The Galaxy Z Fold4 is available in Phantom Black.\n\n**Q19: What is the battery power rating of the Galaxy Z Fold4?**\n- A19: The battery power rating is 4400 mAh.\n\n**Q20: What is included in the box?**\n- A20: The box includes a SIM Tray Ejector and a USB Cable.\n\n**Q21: Who is the manufacturer of the Galaxy Z Fold4?**\n- A21: The manufacturer is Samsung India Pvt Ltd.\n\n**Q22: Where is the Galaxy Z Fold4 manufactured?**\n- A22: The Galaxy Z Fold4 is manufactured in China."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 10: Translation\n",
        "\n",
        "You can use LLMs to take an existing document and translate it from a source to target language. You can also translate to multiple languages at the same time"
      ],
      "metadata": {
        "id": "53QdnJ0M3Vee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You are an expert translator.\n",
        "Translate the given text from English to German.\n",
        "\n",
        "Text: 'Hello, how are you today?'\n",
        "Translation:\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "g-jdFJqJ2cWu",
        "outputId": "afd32922-46b9-438e-f99f-c9dc023b9f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "'Hallo, wie geht es dir heute?'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(prompt, model='gpt-4o')\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "DaxBEl6b2y5U",
        "outputId": "51b73683-dba5-48ef-b7bb-074177287dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Hallo, wie geht es dir heute?"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You are an expert translator.\n",
        "Translate the given text from English to German and Spanish.\n",
        "\n",
        "Text: 'Hello, how are you today?'\n",
        "Translation:\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "ldlb_Avv3gHV",
        "outputId": "eabe4c91-4c60-425f-beeb-3ecd6b51f4d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "German: 'Hallo, wie geht es dir heute?'\nSpanish: 'Hola, ¿cómo estás hoy?'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wh1OfDF43hay"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}