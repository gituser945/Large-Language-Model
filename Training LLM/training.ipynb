{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, trainers, models, normalizers, pre_tokenizers\n",
    "from tokenizers.processors import BertProcessing\n",
    "from tokenizers.normalizers import NFD, Lowercase, StripAccents\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1 : Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 163093\n",
      "{'id': '10', 'url': 'https://hi.wikipedia.org/wiki/%E0%A4%B9%E0%A4%AE%20%E0%A4%B9%E0%A5%8B%E0%A4%82%E0%A4%97%E0%A5%87%20%E0%A4%95%E0%A4%BE%E0%A4%AE%E0%A4%AF%E0%A4%BE%E0%A4%AC', 'title': 'हम होंगे कामयाब', 'text': 'हम होंगे कामयाब ( का गिरिजा कुमार माथुर द्वारा किया गया हिंदी भावानुवाद) एक प्रतिरोध गीत है। यह गीत बीसवीं सदी में नागरिक अधिकार आंदोलन का प्रधान स्वर बना। इस गीत को आमतौर पर \"I\\'ll Overcome Some Day\" (\"आई विल ओवरकम सम डे\") से काव्यावतरित माना जाता है, जो चार्ल्स अल्बर्ट टिंडले द्वारा गाया गया था और जिसे 1900 में पहली बार प्रकाशित किया गया था।\\n\\nसन्दर्भ\\nHum Honge Kamyab Lyrics \\nनागरिक अधिकार आंदोलन\\nदेशभक्ति के गीत\\nआधार'}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"wikimedia/wikipedia\", \"20231101.hi\", split='train')\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2 : Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After deduplication, dataset size: 158516\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "df.drop_duplicates(subset=[\"text\"], inplace=True)\n",
    "print(f\"After deduplication, dataset size: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3 : BPE Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe_tokenizer(corpus, vocab_size=32000, min_frequency=2):\n",
    "    tokenizer = Tokenizer(models.BPE())\n",
    "    tokenizer.normalizer = normalizers.Sequence([NFD(), Lowercase(), StripAccents()])\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    trainer = trainers.BpeTrainer(vocab_size=vocab_size, min_frequency=min_frequency, special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
    "    tokenizer.train_from_iterator(corpus, trainer=trainer)\n",
    "    tokenizer.post_processor = BertProcessing((\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")), (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")))\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = df[\"text\"].tolist()\n",
    "\n",
    "tokenizer = train_bpe_tokenizer(corpus)\n",
    "\n",
    "tokenizer.save(\"hindi_bpe_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded IDs: [2, 4479, 4256, 515, 4669, 5651, 4716, 548, 553, 3]\n",
      "Encoded Tokens: ['[CLS]', 'हद', 'भष', 'क', 'मडल', 'परशकषण', 'महतवपरण', 'ह', '।', '[SEP]']\n",
      "Decoded Text: हद भष क मडल परशकषण महतवपरण ह ।\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"hindi_bpe_tokenizer.json\")\n",
    "\n",
    "sample_text = \"हिंदी भाषा का मॉडल प्रशिक्षण महत्वपूर्ण है।\"\n",
    "encoded = tokenizer.encode(sample_text)\n",
    "\n",
    "print(\"Encoded IDs:\", encoded.ids)\n",
    "print(\"Encoded Tokens:\", encoded.tokens)\n",
    "\n",
    "decoded = tokenizer.decode(encoded.ids)\n",
    "print(\"Decoded Text:\", decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
